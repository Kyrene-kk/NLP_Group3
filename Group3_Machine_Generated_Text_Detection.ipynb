{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e61dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "# pip install fasttext-langdetect\n",
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c92f3a-d9d8-427b-9e75-31afe927965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from ftlangdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a855c0-a83a-4d1a-896c-b8140944fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(text):\n",
    "    text = text.lower()\n",
    "    res = detect(text=text.replace('\\n', ' '), low_memory=False)\n",
    "    if res['score'] > 0.5: return res['lang']\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5fe2c",
   "metadata": {},
   "source": [
    "# 1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02373311",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06434f6f",
   "metadata": {},
   "source": [
    "## 1.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7423e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "roberta_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "roberta_dev['language'] = [get_language(text) for text in roberta_dev['text']]\n",
    "\n",
    "file = \"prediction/xlm_roberta_base_multi_dev.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "roberta_dev[['roberta_label', 'roberta_prob']] = temp[['label', 'probs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ab444",
   "metadata": {},
   "source": [
    "### 1.1.1 Accuracy for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5478e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82976   0.32900   0.47118      2000\n",
      "           1    0.58154   0.93250   0.71634      2000\n",
      "\n",
      "    accuracy                        0.63075      4000\n",
      "   macro avg    0.70565   0.63075   0.59376      4000\n",
      "weighted avg    0.70565   0.63075   0.59376      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(roberta_dev['label'], roberta_dev['roberta_label'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba594fa7",
   "metadata": {},
   "source": [
    "### 1.1.2 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511deed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ru': {'auc': 0.6693805894308943, 'th_optim': 0.9999693632000001},\n",
       " 'ar': {'auc': 0.9978815261044177, 'th_optim': 0.9999364614},\n",
       " 'de': {'auc': 0.966314, 'th_optim': 0.9999710321},\n",
       " 'overall': {'auc': 0.855895125, 'th_optim': 0.9999693632000001}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_dev_auc_dict = {}\n",
    "languages = ['ru', 'ar', 'de']\n",
    "\n",
    "# Calculate AUC and optimal threshold for each language\n",
    "for lang in languages:\n",
    "    lang_df = roberta_dev[roberta_dev['language'] == lang]\n",
    "    if not lang_df.empty:\n",
    "        fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df['roberta_prob'])\n",
    "        lang_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        roberta_dev_auc_dict[lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(roberta_dev['label'], roberta_dev['roberta_prob'])\n",
    "overall_auc = auc(fpr, tpr)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "roberta_dev_auc_dict['overall'] = {'auc': overall_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "roberta_dev_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ed1d9",
   "metadata": {},
   "source": [
    "## 1.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd94a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "roberta_test['language'] = [get_language(text) for text in roberta_test['text']]\n",
    "\n",
    "file = \"prediction/xlm_roberta_base_multi_test.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "roberta_test[['roberta_label', 'roberta_prob']] = temp[['label', 'probs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb4629",
   "metadata": {},
   "source": [
    "### 1.2.1 Accuracy for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3db4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99756   0.48547   0.65311     20238\n",
      "           1    0.67989   0.99892   0.80909     22140\n",
      "\n",
      "    accuracy                        0.75372     42378\n",
      "   macro avg    0.83872   0.74219   0.73110     42378\n",
      "weighted avg    0.83160   0.75372   0.73460     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(roberta_test['label'], roberta_test['roberta_label'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e54af0",
   "metadata": {},
   "source": [
    "### 1.2.2 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f050c92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'auc': 0.9935276806792759, 'th_optim': 0.9999765158},\n",
       " 'de': {'auc': 0.9910564256358992, 'th_optim': 0.9999238253},\n",
       " 'ar': {'auc': 0.9968044659514713, 'th_optim': 0.9999694824},\n",
       " 'it': {'auc': 0.9993302917734165, 'th_optim': 0.9999756813},\n",
       " 'overall': {'auc': 0.9916376075469752, 'th_optim': 0.9999754429000001}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_test_auc_dict = {}\n",
    "languages = ['en', 'de', 'ar', 'it']\n",
    "\n",
    "# Calculate AUC and optimal threshold for each language\n",
    "for lang in languages:\n",
    "    lang_df = roberta_test[roberta_test['language'] == lang]\n",
    "    if not lang_df.empty:\n",
    "        fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df['roberta_prob'])\n",
    "        lang_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        roberta_test_auc_dict[lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(roberta_test['label'], roberta_test['roberta_prob'])\n",
    "overall_auc = auc(fpr, tpr)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "roberta_test_auc_dict['overall'] = {'auc': overall_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "roberta_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8b3fa",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4be2e",
   "metadata": {},
   "source": [
    "## 1.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d1f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "llama_dev['language'] = [get_language(text) for text in llama_dev['text']]\n",
    "\n",
    "file = \"prediction/llama_multi_dev.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llama_dev[['llama_label', 'llama_prob']] = temp[['label', 'probs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3df2e",
   "metadata": {},
   "source": [
    "### 1.1.1 Accuracy for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f2d20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93404   0.48150   0.63543      2000\n",
      "           1    0.65072   0.96600   0.77762      2000\n",
      "\n",
      "    accuracy                        0.72375      4000\n",
      "   macro avg    0.79238   0.72375   0.70653      4000\n",
      "weighted avg    0.79238   0.72375   0.70653      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llama_dev['label'], llama_dev['llama_label'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4c431",
   "metadata": {},
   "source": [
    "### 1.1.2 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a52f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ru': {'auc': 0.8439441056910568, 'th_optim': 1.0},\n",
       " 'ar': {'auc': 0.9579477911646587, 'th_optim': 0.9990234375},\n",
       " 'de': {'auc': 0.9373279999999999, 'th_optim': 1.0},\n",
       " 'overall': {'auc': 0.9026313749999999, 'th_optim': 1.0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_dev_auc_dict = {}\n",
    "languages = ['ru', 'ar', 'de']\n",
    "\n",
    "# Calculate AUC and optimal threshold for each language\n",
    "for lang in languages:\n",
    "    lang_df = llama_dev[llama_dev['language'] == lang]\n",
    "    if not lang_df.empty:\n",
    "        fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df['llama_prob'])\n",
    "        lang_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        llama_dev_auc_dict[lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(llama_dev['label'], llama_dev['llama_prob'])\n",
    "overall_auc = auc(fpr, tpr)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "llama_dev_auc_dict['overall'] = {'auc': overall_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "llama_dev_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0811148",
   "metadata": {},
   "source": [
    "## 1.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c35d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "llama_test['language'] = [get_language(text) for text in llama_test['text']]\n",
    "\n",
    "file = \"prediction/llama_multi_test.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llama_test[['llama_label', 'llama_prob']] = temp[['label', 'probs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a19dfe",
   "metadata": {},
   "source": [
    "### 1.2.1 Accuracy for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13bdb074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97570   0.70234   0.81676     20238\n",
      "           1    0.78339   0.98401   0.87231     22140\n",
      "\n",
      "    accuracy                        0.84950     42378\n",
      "   macro avg    0.87954   0.84318   0.84453     42378\n",
      "weighted avg    0.87523   0.84950   0.84578     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llama_test['label'], llama_test['llama_label'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07d129",
   "metadata": {},
   "source": [
    "### 1.2.2 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ab7481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'auc': 0.9297217894764578, 'th_optim': 1.0},\n",
       " 'de': {'auc': 0.9666838276130177, 'th_optim': 0.4055175781},\n",
       " 'ar': {'auc': 0.9905688685180518, 'th_optim': 0.99609375},\n",
       " 'it': {'auc': 0.9954626969591409, 'th_optim': 1.0},\n",
       " 'overall': {'auc': 0.9431453061771782, 'th_optim': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_test_auc_dict = {}\n",
    "languages = ['en', 'de', 'ar', 'it']\n",
    "\n",
    "# Calculate AUC and optimal threshold for each language\n",
    "for lang in languages:\n",
    "    lang_df = llama_test[llama_test['language'] == lang]\n",
    "    if not lang_df.empty:\n",
    "        fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df['llama_prob'])\n",
    "        lang_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        llama_test_auc_dict[lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(llama_test['label'], llama_test['llama_prob'])\n",
    "overall_auc = auc(fpr, tpr)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "llama_test_auc_dict['overall'] = {'auc': overall_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "llama_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3595982",
   "metadata": {},
   "source": [
    "# 2. Metric-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e59e11",
   "metadata": {},
   "source": [
    "## 2.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ec29e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "s5_dev['language'] = [get_language(text) for text in s5_dev['text']]\n",
    "\n",
    "file = \"prediction/rank_entropy_ll_logrank_dev_statistic_metric.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "s5_dev[['rank', 'entropy', 'likelihood', 'log_rank']] = temp[['rank', 'entropy', 'likelihood', 'log_rank']]\n",
    "\n",
    "file = \"prediction/binocular_metric_dev.csv\"\n",
    "temp = pd.read_csv(file)\n",
    "s5_dev[['binocular']] = temp[['binocular']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b50a64",
   "metadata": {},
   "source": [
    "### 2.1.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8cc6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': {'auc': 0.5227096250000001,\n",
       "  'th_optim': -194.61175537109375,\n",
       "  'ru': {'auc': 0.3832794715447154, 'th_optim': -64.93841552734375},\n",
       "  'de': {'auc': 0.7299720000000001, 'th_optim': -194.61175537109375},\n",
       "  'ar': {'auc': 0.7720020080321286, 'th_optim': -5.068426132202148}},\n",
       " 'entropy': {'auc': 0.54484175,\n",
       "  'th_optim': 1.805957436561584,\n",
       "  'ru': {'auc': 0.7248231707317074, 'th_optim': 1.805957436561584},\n",
       "  'de': {'auc': 0.3933, 'th_optim': 2.955816268920898},\n",
       "  'ar': {'auc': 0.3155582329317269, 'th_optim': 1.7562482357025142}},\n",
       " 'likelihood': {'auc': 0.5027961249999999,\n",
       "  'th_optim': -2.023075819015503,\n",
       "  'ru': {'auc': 0.34253607723577234, 'th_optim': -2.04640245437622},\n",
       "  'de': {'auc': 0.74556, 'th_optim': -3.606225967407226},\n",
       "  'ar': {'auc': 0.8104979919678715, 'th_optim': -2.023049831390381}},\n",
       " 'log_rank': {'auc': 0.50150075,\n",
       "  'th_optim': -0.9323371648788451,\n",
       "  'ru': {'auc': 0.34744207317073167, 'th_optim': -0.9259398579597471},\n",
       "  'de': {'auc': 0.746356, 'th_optim': -2.008877754211426},\n",
       "  'ar': {'auc': 0.7871847389558233, 'th_optim': -0.9462776184082031}},\n",
       " 'binocular': {'auc': 0.5488975,\n",
       "  'th_optim': 0.987603307,\n",
       "  'ru': {'auc': 0.6066819105691057, 'th_optim': 0.939086318},\n",
       "  'de': {'auc': 0.608414, 'th_optim': 0.987730086},\n",
       "  'ar': {'auc': 0.4192871485943775, 'th_optim': 0.994475126}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['ru', 'de', 'ar']\n",
    "s5_dev_auc_dict = {}\n",
    "\n",
    "for model in [x for x in s5_dev.columns.to_list()[6:]]:\n",
    "    labels = s5_dev['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, s5_dev[model])\n",
    "    s5_dev_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = s5_dev[s5_dev.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        s5_dev_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "s5_dev_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb070117",
   "metadata": {},
   "source": [
    "### 2.1.2 Accuracy for S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c54331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() #'rank', 'entropy', 'likelihood', 'log-rank', 'binocular'\n",
    "selected = 'rank'\n",
    "use_th = 'th_optim'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_dev['language'], s5_dev[selected])]\n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_dev['language'], s5_dev[selected])]\n",
    "selected = 'likelihood'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_dev['language'], s5_dev[selected])]\n",
    "selected = 'log_rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_dev['language'], s5_dev[selected])]\n",
    "selected = 'binocular'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_dev['language'], s5_dev[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fc0e7",
   "metadata": {},
   "source": [
    "#### rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fb84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.67788   0.38300   0.48946      2000\n",
      "           1    0.57003   0.81800   0.67187      2000\n",
      "\n",
      "    accuracy                        0.60050      4000\n",
      "   macro avg    0.62396   0.60050   0.58066      4000\n",
      "weighted avg    0.62396   0.60050   0.58066      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_dev['label'], s5['rank'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e11c4",
   "metadata": {},
   "source": [
    "#### entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983ed8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77078   0.30600   0.43808      2000\n",
      "           1    0.56706   0.90900   0.69842      2000\n",
      "\n",
      "    accuracy                        0.60750      4000\n",
      "   macro avg    0.66892   0.60750   0.56825      4000\n",
      "weighted avg    0.66892   0.60750   0.56825      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_dev['label'], s5['entropy'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa49ca",
   "metadata": {},
   "source": [
    "#### likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3dc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77197   0.34700   0.47879      2000\n",
      "           1    0.57885   0.89750   0.70378      2000\n",
      "\n",
      "    accuracy                        0.62225      4000\n",
      "   macro avg    0.67541   0.62225   0.59128      4000\n",
      "weighted avg    0.67541   0.62225   0.59128      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_dev['label'], s5['likelihood'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2681edb",
   "metadata": {},
   "source": [
    "#### log_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b996919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.73663   0.36500   0.48813      2000\n",
      "           1    0.57793   0.86950   0.69435      2000\n",
      "\n",
      "    accuracy                        0.61725      4000\n",
      "   macro avg    0.65728   0.61725   0.59124      4000\n",
      "weighted avg    0.65728   0.61725   0.59124      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_dev['label'], s5['log_rank'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411f321",
   "metadata": {},
   "source": [
    "#### binocular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b0ecf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.57080   0.65300   0.60914      2000\n",
      "           1    0.59463   0.50900   0.54849      2000\n",
      "\n",
      "    accuracy                        0.58100      4000\n",
      "   macro avg    0.58272   0.58100   0.57882      4000\n",
      "weighted avg    0.58272   0.58100   0.57882      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_dev['label'], s5['binocular'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7903a",
   "metadata": {},
   "source": [
    "## 2.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91dee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "s5_test['language'] = [get_language(text) for text in s5_test['text']]\n",
    "\n",
    "file = \"prediction/rank_entropy_ll_logrank_test_statistic_metric.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "s5_test[['rank', 'entropy', 'likelihood', 'log_rank']] = temp[['rank', 'entropy', 'likelihood', 'log_rank']]\n",
    "\n",
    "file = \"prediction/binocular_metric_test.csv\"\n",
    "temp = pd.read_csv(file)\n",
    "s5_test[['binocular']] = temp[['binocular']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46217e66",
   "metadata": {},
   "source": [
    "### 2.2.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2bbf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': {'auc': 0.734150589690006,\n",
       "  'th_optim': -48.46562576293945,\n",
       "  'en': {'auc': 0.8843203738822354, 'th_optim': -48.46562576293945},\n",
       "  'it': {'auc': 0.7366540665997139, 'th_optim': -319.14190673828125},\n",
       "  'de': {'auc': 0.8188589359102523, 'th_optim': -192.0410614013672},\n",
       "  'ar': {'auc': 0.792478392750625, 'th_optim': -4.099065780639648}},\n",
       " 'entropy': {'auc': 0.23592029019081243,\n",
       "  'th_optim': inf,\n",
       "  'en': {'auc': 0.05007472374873752, 'th_optim': inf},\n",
       "  'it': {'auc': 0.12014288120423056, 'th_optim': 3.541979074478149},\n",
       "  'de': {'auc': 0.28796329001443965, 'th_optim': inf},\n",
       "  'ar': {'auc': 0.14586139813000068, 'th_optim': inf}},\n",
       " 'likelihood': {'auc': 0.7904263864796635,\n",
       "  'th_optim': -2.735857248306274,\n",
       "  'en': {'auc': 0.9652668069951141, 'th_optim': -2.718686580657959},\n",
       "  'it': {'auc': 0.8302371475957161, 'th_optim': -4.318907737731934},\n",
       "  'de': {'auc': 0.9068092857936243, 'th_optim': -3.423327445983886},\n",
       "  'ar': {'auc': 0.936290569684399, 'th_optim': -2.009902715682983}},\n",
       " 'log_rank': {'auc': 0.7789901203233464,\n",
       "  'th_optim': -1.307896137237548,\n",
       "  'en': {'auc': 0.9656900407315608, 'th_optim': -1.307896137237548},\n",
       "  'it': {'auc': 0.8131632187007596, 'th_optim': -2.570108652114868},\n",
       "  'de': {'auc': 0.9150423192269243, 'th_optim': -1.914580821990966},\n",
       "  'ar': {'auc': 0.9222891446121936, 'th_optim': -0.936908066272735}},\n",
       " 'binocular': {'auc': 0.4949722545163324,\n",
       "  'th_optim': 1.061643839,\n",
       "  'en': {'auc': 0.49328733993989105, 'th_optim': 1.064748168},\n",
       "  'it': {'auc': 0.48862780371902126, 'th_optim': 0.737762213},\n",
       "  'de': {'auc': 0.4979852271465067, 'th_optim': 0.743902445},\n",
       "  'ar': {'auc': 0.5274009112484611, 'th_optim': 0.900662243}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['en', 'it', 'de', 'ar']\n",
    "s5_test_auc_dict = {}\n",
    "\n",
    "for model in [x for x in s5_test.columns.to_list()[4:]]:\n",
    "    labels = s5_test['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, s5_test[model])\n",
    "    s5_test_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = s5_test[s5_test.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        s5_test_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "s5_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef4999",
   "metadata": {},
   "source": [
    "### 2.2.2 Accuracy for S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c94dcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() #'rank', 'entropy', 'likelihood', 'log-rank', 'binocular'\n",
    "selected = 'rank'\n",
    "use_th = 'th_optim'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_test['language'], s5_test[selected])]\n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_test['language'], s5_test[selected])]\n",
    "selected = 'likelihood'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_test['language'], s5_test[selected])]\n",
    "selected = 'log_rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_test['language'], s5_test[selected])]\n",
    "selected = 'binocular'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=s5_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=s5_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(s5_test['language'], s5_test[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b4ac9",
   "metadata": {},
   "source": [
    "#### rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3cc9747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.74858   0.79430   0.77076     20238\n",
      "           1    0.80085   0.75614   0.77786     22140\n",
      "\n",
      "    accuracy                        0.77436     42378\n",
      "   macro avg    0.77472   0.77522   0.77431     42378\n",
      "weighted avg    0.77589   0.77436   0.77447     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_test['label'], s5['rank'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956940fc",
   "metadata": {},
   "source": [
    "#### entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1409c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.47385   0.85003   0.60849     20238\n",
      "           1    0.50025   0.13722   0.21536     22140\n",
      "\n",
      "    accuracy                        0.47763     42378\n",
      "   macro avg    0.48705   0.49363   0.41193     42378\n",
      "weighted avg    0.48764   0.47763   0.40310     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_test['label'], s5['entropy'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0470e723",
   "metadata": {},
   "source": [
    "#### likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f432b104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.86879   0.85167   0.86014     20238\n",
      "           1    0.86681   0.88243   0.87455     22140\n",
      "\n",
      "    accuracy                        0.86774     42378\n",
      "   macro avg    0.86780   0.86705   0.86735     42378\n",
      "weighted avg    0.86776   0.86774   0.86767     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_test['label'], s5['likelihood'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c836c6",
   "metadata": {},
   "source": [
    "#### log_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceac4316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87622   0.84297   0.85927     20238\n",
      "           1    0.86127   0.89115   0.87595     22140\n",
      "\n",
      "    accuracy                        0.86814     42378\n",
      "   macro avg    0.86875   0.86706   0.86761     42378\n",
      "weighted avg    0.86841   0.86814   0.86799     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_test['label'], s5['log_rank'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b6643",
   "metadata": {},
   "source": [
    "#### binocular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7db2a167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.47238   0.67867   0.55704     20238\n",
      "           1    0.51113   0.30709   0.38367     22140\n",
      "\n",
      "    accuracy                        0.48454     42378\n",
      "   macro avg    0.49175   0.49288   0.47036     42378\n",
      "weighted avg    0.49262   0.48454   0.46647     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(s5_test['label'], s5['binocular'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411c203",
   "metadata": {},
   "source": [
    "# 3. LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e6e82",
   "metadata": {},
   "source": [
    "## 3.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c5b1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "llm_dev['language'] = [get_language(text) for text in llm_dev['text']]\n",
    "\n",
    "file = \"prediction/falcon_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm_dev['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm_dev['mistral'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c65d67",
   "metadata": {},
   "source": [
    "### 3.1.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "824fa911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falcon': {'auc': 0.877502625,\n",
       "  'th_optim': 0.1291503906,\n",
       "  'ru': {'auc': 0.9594547764227643, 'th_optim': 0.1722412109},\n",
       "  'de': {'auc': 0.8454059999999999, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.7347630522088353, 'th_optim': 0.0041198730000000005}},\n",
       " 'mistral': {'auc': 0.9039201250000001,\n",
       "  'th_optim': 1.0,\n",
       "  'ru': {'auc': 0.9077169715447154, 'th_optim': 0.5888671875},\n",
       "  'de': {'auc': 0.966332, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.844726907630522, 'th_optim': 1.0}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['ru', 'de', 'ar']\n",
    "llm_dev_auc_dict = {}\n",
    "\n",
    "for model in [x for x in llm_dev.columns.to_list()[6:]]:\n",
    "    labels = llm_dev['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, llm_dev[model])\n",
    "    llm_dev_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = llm_dev[llm_dev.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        llm_dev_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "llm_dev_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0bd6e",
   "metadata": {},
   "source": [
    "### 3.1.2 Accuracy for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc95c12",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd4054e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral = pd.DataFrame()\n",
    "selected = 'mistral'\n",
    "use_th = 'th_optim'\n",
    "mistral[selected] = [1 if (lang in languages) and (prob>=llm_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm_dev['language'], llm_dev[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b50f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90067   0.87950   0.88996      2000\n",
      "           1    0.88227   0.90300   0.89251      2000\n",
      "\n",
      "    accuracy                        0.89125      4000\n",
      "   macro avg    0.89147   0.89125   0.89123      4000\n",
      "weighted avg    0.89147   0.89125   0.89123      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm_dev['label'], mistral['mistral'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556b302",
   "metadata": {},
   "source": [
    "#### falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16392f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon = pd.DataFrame()\n",
    "selected = 'falcon'\n",
    "use_th = 'th_optim'\n",
    "falcon[selected] = [1 if (lang in languages) and (prob>=llm_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm_dev['language'], llm_dev[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7ba8863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87827   0.82250   0.84947      2000\n",
      "           1    0.83310   0.88600   0.85874      2000\n",
      "\n",
      "    accuracy                        0.85425      4000\n",
      "   macro avg    0.85568   0.85425   0.85410      4000\n",
      "weighted avg    0.85568   0.85425   0.85410      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm_dev['label'], falcon['falcon'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17fb09",
   "metadata": {},
   "source": [
    "## 3.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe337cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "llm_test['language'] = [get_language(text) for text in llm_test['text']]\n",
    "\n",
    "file = \"prediction/falcon_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm_test['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm_test['mistral'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68985ff4",
   "metadata": {},
   "source": [
    "### 3.2.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9062dbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falcon': {'auc': 0.9491783302637191,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9370427968754189, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9976826838099255, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9662147617460847, 'th_optim': 0.0046272278000000005},\n",
       "  'ar': {'auc': 0.9901645541391457, 'th_optim': 0.9340820312}},\n",
       " 'mistral': {'auc': 0.9730138876725591,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9816146685862734, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9962090330731164, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9685180495390425, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.8002750425617939, 'th_optim': 1.0}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['en', 'it', 'de', 'ar']\n",
    "llm_test_auc_dict = {}\n",
    "\n",
    "for model in [x for x in llm_test.columns.to_list()[4:]]:\n",
    "    labels = llm_test['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, llm_test[model])\n",
    "    llm_test_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = llm_test[llm_test.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        llm_test_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "llm_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716100f",
   "metadata": {},
   "source": [
    "### 3.2.2 Accuracy for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240df387",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dc9ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral = pd.DataFrame()\n",
    "selected = 'mistral'\n",
    "use_th = 'th_optim'\n",
    "mistral[selected] = [1 if (lang in languages) and (prob>=llm_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm_test['language'], llm_test[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75b4c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99647   0.94723   0.97122     20238\n",
      "           1    0.95385   0.99693   0.97491     22140\n",
      "\n",
      "    accuracy                        0.97319     42378\n",
      "   macro avg    0.97516   0.97208   0.97307     42378\n",
      "weighted avg    0.97420   0.97319   0.97315     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm_test['label'], mistral['mistral'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba14fc",
   "metadata": {},
   "source": [
    "#### falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08d3880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon = pd.DataFrame()\n",
    "selected = 'falcon'\n",
    "use_th = 'th_optim'\n",
    "falcon[selected] = [1 if (lang in languages) and (prob>=llm_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm_test['language'], llm_test[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "826530f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96545   0.91551   0.93982     20238\n",
      "           1    0.92625   0.97005   0.94765     22140\n",
      "\n",
      "    accuracy                        0.94400     42378\n",
      "   macro avg    0.94585   0.94278   0.94373     42378\n",
      "weighted avg    0.94497   0.94400   0.94391     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm_test['label'], falcon['falcon'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502905b9",
   "metadata": {},
   "source": [
    "# 4. LLM2 (MF, ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23396e9a",
   "metadata": {},
   "source": [
    "## 4.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ee3a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "llm2_dev['language'] = [get_language(text) for text in llm2_dev['text']]\n",
    "\n",
    "file = \"prediction/falcon_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_dev['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_dev['mistral'] = temp['probs']\n",
    "\n",
    "file = \"prediction/llama_multi_dev.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_dev['llama'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca399f",
   "metadata": {},
   "source": [
    "### 4.1.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feb16dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falcon': {'auc': 0.877502625,\n",
       "  'th_optim': 0.1291503906,\n",
       "  'ru': {'auc': 0.9594547764227643, 'th_optim': 0.1722412109},\n",
       "  'de': {'auc': 0.8454059999999999, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.7347630522088353, 'th_optim': 0.0041198730000000005}},\n",
       " 'mistral': {'auc': 0.9039201250000001,\n",
       "  'th_optim': 1.0,\n",
       "  'ru': {'auc': 0.9077169715447154, 'th_optim': 0.5888671875},\n",
       "  'de': {'auc': 0.966332, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.844726907630522, 'th_optim': 1.0}},\n",
       " 'llama': {'auc': 0.9026313749999999,\n",
       "  'th_optim': 1.0,\n",
       "  'ru': {'auc': 0.8439441056910568, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9373279999999999, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.9579477911646587, 'th_optim': 0.9990234375}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = ['ru', 'de', 'ar']\n",
    "llm2_dev_auc_dict = {'falcon': {}, 'mistral': {}, 'llama': {}}\n",
    "\n",
    "for model in [x for x in llm2_dev.columns.to_list()[6:]]:\n",
    "    fpr, tpr, thresholds = roc_curve(llm2_dev['label'], llm2_dev[model])\n",
    "    overall_auc = auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    llm2_dev_auc_dict[model]['auc'] = overall_auc\n",
    "    llm2_dev_auc_dict[model]['th_optim'] = optimal_threshold\n",
    "\n",
    "    for lang in languages:\n",
    "        lang_df = llm2_dev[llm2_dev['language'] == lang]\n",
    "        if not lang_df.empty:\n",
    "            fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df[model])\n",
    "            lang_auc = auc(fpr, tpr)\n",
    "            optimal_idx = np.argmax(tpr - fpr)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            llm2_dev_auc_dict[model][lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "llm2_dev_auc_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791433e",
   "metadata": {},
   "source": [
    "### 4.1.2 dev set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e8c79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\3360981368.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['soft_vote'] = llm2.mean(axis=1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\3360981368.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['language'] = llm2_dev['language']\n"
     ]
    }
   ],
   "source": [
    "llm2 = llm2_dev[['llama', 'mistral']]   # ML\n",
    "llm2['soft_vote'] = llm2.mean(axis=1)\n",
    "llm2['language'] = llm2_dev['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72a1dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_th_optims = [llm2_dev_auc_dict['llama']['th_optim'], llm2_dev_auc_dict['mistral']['th_optim']]\n",
    "total_average_th_optim = sum(total_th_optims) / len(total_th_optims)\n",
    "\n",
    "average_th_optim = {'th_optim': total_average_th_optim}\n",
    "\n",
    "for lang in languages:\n",
    "    th_optim_llama = llm2_dev_auc_dict['llama'].get(lang, {}).get('th_optim', 0)\n",
    "    th_optim_mistral = llm2_dev_auc_dict['mistral'].get(lang, {}).get('th_optim', 0)\n",
    "    average_th_optim[lang] = (th_optim_llama + th_optim_mistral) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a4900b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\2558241900.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['prediction'] = [1 if (lang in languages) and (prob>=average_th_optim[lang]) else 1 if (lang not in languages) and (prob>=average_th_optim[\"th_optim\"]) else 0 for lang, prob in zip(llm2['language'], llm2[\"soft_vote\"])]\n"
     ]
    }
   ],
   "source": [
    "# calculate the threshold mean\n",
    "llm2['prediction'] = [1 if (lang in languages) and (prob>=average_th_optim[lang]) else 1 if (lang not in languages) and (prob>=average_th_optim[\"th_optim\"]) else 0 for lang, prob in zip(llm2['language'], llm2[\"soft_vote\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5dce2a",
   "metadata": {},
   "source": [
    "### 4.1.3 Accuracy for LLM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40304b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88355   0.95600   0.91835      2000\n",
      "           1    0.95207   0.87400   0.91137      2000\n",
      "\n",
      "    accuracy                        0.91500      4000\n",
      "   macro avg    0.91781   0.91500   0.91486      4000\n",
      "weighted avg    0.91781   0.91500   0.91486      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm2_dev['label'], llm2['prediction'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2279319",
   "metadata": {},
   "source": [
    "## 4.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ad6f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "llm2_test['language'] = [get_language(text) for text in llm2_test['text']]\n",
    "\n",
    "file = \"prediction/falcon_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_test['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_test['mistral'] = temp['probs']\n",
    "\n",
    "file = \"prediction/llama_multi_test.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2_test['llama'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4aaea",
   "metadata": {},
   "source": [
    "### 4.2.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffe0b25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falcon': {'auc': 0.9491783302637191,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9370427968754189, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9976826838099255, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9662147617460847, 'th_optim': 0.0046272278000000005},\n",
       "  'ar': {'auc': 0.9901645541391457, 'th_optim': 0.9340820312}},\n",
       " 'mistral': {'auc': 0.9730138876725591,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9816146685862734, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9962090330731164, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9685180495390425, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.8002750425617939, 'th_optim': 1.0}},\n",
       " 'llama': {'auc': 0.9431453061771782,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9297217894764578, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9954626969591409, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9666838276130177, 'th_optim': 0.4055175781},\n",
       "  'ar': {'auc': 0.9905688685180518, 'th_optim': 0.99609375}}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = ['en', 'it', 'de', 'ar']\n",
    "llm2_test_auc_dict = {'falcon': {}, 'mistral': {}, 'llama':{}}\n",
    "\n",
    "for model in [x for x in llm2_dev.columns.to_list()[6:]]:\n",
    "    fpr, tpr, thresholds = roc_curve(llm2_test['label'], llm2_test[model])\n",
    "    overall_auc = auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    llm2_test_auc_dict[model]['auc'] = overall_auc\n",
    "    llm2_test_auc_dict[model]['th_optim'] = optimal_threshold\n",
    "\n",
    "    for lang in languages:\n",
    "        lang_df = llm2_test[llm2_test['language'] == lang]\n",
    "        if not lang_df.empty:\n",
    "            fpr, tpr, thresholds = roc_curve(lang_df['label'], lang_df[model])\n",
    "            lang_auc = auc(fpr, tpr)\n",
    "            optimal_idx = np.argmax(tpr - fpr)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            llm2_test_auc_dict[model][lang] = {'auc': lang_auc, 'th_optim': optimal_threshold}\n",
    "\n",
    "llm2_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b8da7",
   "metadata": {},
   "source": [
    "### 4.2.2 test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c76d3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\2084080351.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['soft_vote'] = llm2.mean(axis=1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\2084080351.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['language'] = llm2_test['language']\n"
     ]
    }
   ],
   "source": [
    "llm2 = llm2_test[['llama', 'mistral']]  # ML\n",
    "llm2['soft_vote'] = llm2.mean(axis=1)\n",
    "llm2['language'] = llm2_test['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "803ff135",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_th_optims = [llm2_test_auc_dict['llama']['th_optim'], llm2_test_auc_dict['mistral']['th_optim']]\n",
    "total_average_th_optim = sum(total_th_optims) / len(total_th_optims)\n",
    "\n",
    "average_th_optim = {'th_optim': total_average_th_optim}\n",
    "\n",
    "for lang in languages:\n",
    "    th_optim_llama = llm2_test_auc_dict['llama'].get(lang, {}).get('th_optim', 0)\n",
    "    th_optim_mistral = llm2_test_auc_dict['mistral'].get(lang, {}).get('th_optim', 0)\n",
    "    average_th_optim[lang] = (th_optim_llama + th_optim_mistral) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "152ed09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26960\\2558241900.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llm2['prediction'] = [1 if (lang in languages) and (prob>=average_th_optim[lang]) else 1 if (lang not in languages) and (prob>=average_th_optim[\"th_optim\"]) else 0 for lang, prob in zip(llm2['language'], llm2[\"soft_vote\"])]\n"
     ]
    }
   ],
   "source": [
    "# calculate the threshold mean\n",
    "llm2['prediction'] = [1 if (lang in languages) and (prob>=average_th_optim[lang]) else 1 if (lang not in languages) and (prob>=average_th_optim[\"th_optim\"]) else 0 for lang, prob in zip(llm2['language'], llm2[\"soft_vote\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06198c",
   "metadata": {},
   "source": [
    "### 4.2.3 Accuracy for LLM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48aa65b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97571   0.98058   0.97814     20238\n",
      "           1    0.98217   0.97769   0.97992     22140\n",
      "\n",
      "    accuracy                        0.97907     42378\n",
      "   macro avg    0.97894   0.97913   0.97903     42378\n",
      "weighted avg    0.97908   0.97907   0.97907     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm2_test['label'], llm2['prediction'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4aaa8",
   "metadata": {},
   "source": [
    "# 5. LLM2S3 (MF-ELL, MF-REB, MF-ELB, ML-ELL, ML-REB, ML-ELB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17189e",
   "metadata": {},
   "source": [
    " ## 5.1 dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "008542fd-f0e5-4140-8a3b-72943fbfcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2s3_dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "llm2s3_dev['language'] = [get_language(text) for text in llm2s3_dev['text']]\n",
    "\n",
    "file = \"prediction/rank_entropy_ll_logrank_dev_statistic_metric.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_dev[['entropy', 'likelihood', 'log_rank', 'rank']] = temp[['entropy', 'likelihood', 'log_rank', 'rank']]\n",
    "\n",
    "file = \"prediction/binocular_metric_dev.csv\"\n",
    "temp = pd.read_csv(file)\n",
    "llm2s3_dev[['binocular']] = temp[['binocular']]\n",
    "\n",
    "file = \"prediction/falcon_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_dev['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_dev_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_dev['mistral'] = temp['probs']\n",
    "\n",
    "file = \"prediction/llama_multi_dev.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_dev['llama'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fb8e4",
   "metadata": {},
   "source": [
    "### 5.1.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e95febef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entropy': {'auc': 0.54484175,\n",
       "  'th_optim': 1.805957436561584,\n",
       "  'ru': {'auc': 0.7248231707317074, 'th_optim': 1.805957436561584},\n",
       "  'de': {'auc': 0.3933, 'th_optim': 2.955816268920898},\n",
       "  'ar': {'auc': 0.3155582329317269, 'th_optim': 1.7562482357025142}},\n",
       " 'likelihood': {'auc': 0.5027961249999999,\n",
       "  'th_optim': -2.023075819015503,\n",
       "  'ru': {'auc': 0.34253607723577234, 'th_optim': -2.04640245437622},\n",
       "  'de': {'auc': 0.74556, 'th_optim': -3.606225967407226},\n",
       "  'ar': {'auc': 0.8104979919678715, 'th_optim': -2.023049831390381}},\n",
       " 'log_rank': {'auc': 0.50150075,\n",
       "  'th_optim': -0.9323371648788451,\n",
       "  'ru': {'auc': 0.34744207317073167, 'th_optim': -0.9259398579597471},\n",
       "  'de': {'auc': 0.746356, 'th_optim': -2.008877754211426},\n",
       "  'ar': {'auc': 0.7871847389558233, 'th_optim': -0.9462776184082031}},\n",
       " 'rank': {'auc': 0.5227096250000001,\n",
       "  'th_optim': -194.61175537109375,\n",
       "  'ru': {'auc': 0.3832794715447154, 'th_optim': -64.93841552734375},\n",
       "  'de': {'auc': 0.7299720000000001, 'th_optim': -194.61175537109375},\n",
       "  'ar': {'auc': 0.7720020080321286, 'th_optim': -5.068426132202148}},\n",
       " 'binocular': {'auc': 0.5488975,\n",
       "  'th_optim': 0.987603307,\n",
       "  'ru': {'auc': 0.6066819105691057, 'th_optim': 0.939086318},\n",
       "  'de': {'auc': 0.608414, 'th_optim': 0.987730086},\n",
       "  'ar': {'auc': 0.4192871485943775, 'th_optim': 0.994475126}},\n",
       " 'falcon': {'auc': 0.877502625,\n",
       "  'th_optim': 0.1291503906,\n",
       "  'ru': {'auc': 0.9594547764227643, 'th_optim': 0.1722412109},\n",
       "  'de': {'auc': 0.8454059999999999, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.7347630522088353, 'th_optim': 0.0041198730000000005}},\n",
       " 'mistral': {'auc': 0.9039201250000001,\n",
       "  'th_optim': 1.0,\n",
       "  'ru': {'auc': 0.9077169715447154, 'th_optim': 0.5888671875},\n",
       "  'de': {'auc': 0.966332, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.844726907630522, 'th_optim': 1.0}},\n",
       " 'llama': {'auc': 0.9026313749999999,\n",
       "  'th_optim': 1.0,\n",
       "  'ru': {'auc': 0.8439441056910568, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9373279999999999, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.9579477911646587, 'th_optim': 0.9990234375}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['ru', 'de', 'ar']\n",
    "llm2S3_dev_auc_dict = {}\n",
    "\n",
    "for model in [x for x in llm2s3_dev.columns.to_list()[6:]]:\n",
    "    labels = llm2s3_dev['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, llm2s3_dev[model])\n",
    "    llm2S3_dev_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = llm2s3_dev[llm2s3_dev.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        llm2S3_dev_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "llm2S3_dev_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c171f8b-971a-4918-9b3a-097202a3b0bd",
   "metadata": {},
   "source": [
    "### 5.1.2 Dev set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e68f789-923d-4c22-96d0-14a32c68f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_th = 'th_optim'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e59f43",
   "metadata": {},
   "source": [
    "#### Statistical detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a8bdebd-b5ae-4a12-8b6b-2d42e6f27d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() \n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_dev['language'], llm2s3_dev[selected])]\n",
    "selected = 'rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_dev['language'], llm2s3_dev[selected])]\n",
    "selected = 'binocular'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_dev['language'], llm2s3_dev[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11fa6b",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff874f0f-d4c2-41b3-8e94-6a34cd6fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2s3 = pd.DataFrame()\n",
    "selected = 'llama'\n",
    "llm2s3[selected] = [1 if (lang in languages) and (prob>=llm2S3_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_dev['language'], llm2s3_dev[selected])]\n",
    "selected = 'mistral'\n",
    "llm2s3[selected] = [1 if (lang in languages) and (prob>=llm2S3_dev_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_dev_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_dev['language'], llm2s3_dev[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0ec44",
   "metadata": {},
   "source": [
    "#### Two-step majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0d433db-f1b4-4cd1-b81f-ae8ea8080bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical part majority voting\n",
    "llm2s3_dev['s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(s5['entropy'], s5['rank'], s5['binocular'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edd1891c-d668-4ea7-becd-529f9e32b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final majority voting\n",
    "llm2s3_dev['llm2s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(llm2s3['llama'], llm2s3['mistral'], llm2s3_dev['s3'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63e9bd",
   "metadata": {},
   "source": [
    "### 5.1.3 Accuracy for LLM2S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0aa5a5ec-f9c8-4a56-aa44-78042d41074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92857   0.88400   0.90574      2000\n",
      "           1    0.88931   0.93200   0.91016      2000\n",
      "\n",
      "    accuracy                        0.90800      4000\n",
      "   macro avg    0.90894   0.90800   0.90795      4000\n",
      "weighted avg    0.90894   0.90800   0.90795      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm2s3_dev['label'], llm2s3_dev['llm2s3'], digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01f8ae-c1ad-4cfe-bd15-0de7f31e5235",
   "metadata": {},
   "source": [
    "## 5.2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc392bc9-6a89-47db-a91c-fe4efa7d202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2s3_test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "llm2s3_test['language'] = [get_language(text) for text in llm2s3_test['text']]\n",
    "\n",
    "file = \"prediction/rank_entropy_ll_logrank_test_statistic_metric.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_test[['entropy', 'likelihood', 'log_rank', 'rank']] = temp[['entropy', 'likelihood', 'log_rank', 'rank']]\n",
    "\n",
    "file = \"prediction/binocular_metric_test.csv\"\n",
    "temp = pd.read_csv(file)\n",
    "llm2s3_test[['binocular']] = temp[['binocular']]\n",
    "\n",
    "file = \"prediction/falcon_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_test['falcon'] = temp['probs']\n",
    "\n",
    "file = \"prediction/mistral_test_multi.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_test['mistral'] = temp['probs']\n",
    "\n",
    "file = \"prediction/llama_multi_test.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "llm2s3_test['llama'] = temp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a336fb",
   "metadata": {},
   "source": [
    "### 5.2.1 Optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df706fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entropy': {'auc': 0.23592029019081243,\n",
       "  'th_optim': inf,\n",
       "  'en': {'auc': 0.05007472374873752, 'th_optim': inf},\n",
       "  'it': {'auc': 0.12014288120423056, 'th_optim': 3.541979074478149},\n",
       "  'de': {'auc': 0.28796329001443965, 'th_optim': inf},\n",
       "  'ar': {'auc': 0.14586139813000068, 'th_optim': inf}},\n",
       " 'likelihood': {'auc': 0.7904263864796635,\n",
       "  'th_optim': -2.735857248306274,\n",
       "  'en': {'auc': 0.9652668069951141, 'th_optim': -2.718686580657959},\n",
       "  'it': {'auc': 0.8302371475957161, 'th_optim': -4.318907737731934},\n",
       "  'de': {'auc': 0.9068092857936243, 'th_optim': -3.423327445983886},\n",
       "  'ar': {'auc': 0.936290569684399, 'th_optim': -2.009902715682983}},\n",
       " 'log_rank': {'auc': 0.7789901203233464,\n",
       "  'th_optim': -1.307896137237548,\n",
       "  'en': {'auc': 0.9656900407315608, 'th_optim': -1.307896137237548},\n",
       "  'it': {'auc': 0.8131632187007596, 'th_optim': -2.570108652114868},\n",
       "  'de': {'auc': 0.9150423192269243, 'th_optim': -1.914580821990966},\n",
       "  'ar': {'auc': 0.9222891446121936, 'th_optim': -0.936908066272735}},\n",
       " 'rank': {'auc': 0.734150589690006,\n",
       "  'th_optim': -48.46562576293945,\n",
       "  'en': {'auc': 0.8843203738822354, 'th_optim': -48.46562576293945},\n",
       "  'it': {'auc': 0.7366540665997139, 'th_optim': -319.14190673828125},\n",
       "  'de': {'auc': 0.8188589359102523, 'th_optim': -192.0410614013672},\n",
       "  'ar': {'auc': 0.792478392750625, 'th_optim': -4.099065780639648}},\n",
       " 'binocular': {'auc': 0.4949722545163324,\n",
       "  'th_optim': 1.061643839,\n",
       "  'en': {'auc': 0.49328733993989105, 'th_optim': 1.064748168},\n",
       "  'it': {'auc': 0.48862780371902126, 'th_optim': 0.737762213},\n",
       "  'de': {'auc': 0.4979852271465067, 'th_optim': 0.743902445},\n",
       "  'ar': {'auc': 0.5274009112484611, 'th_optim': 0.900662243}},\n",
       " 'falcon': {'auc': 0.9491783302637191,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9370427968754189, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9976826838099255, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9662147617460847, 'th_optim': 0.0046272278000000005},\n",
       "  'ar': {'auc': 0.9901645541391457, 'th_optim': 0.9340820312}},\n",
       " 'mistral': {'auc': 0.9730138876725591,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9816146685862734, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9962090330731164, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9685180495390425, 'th_optim': 1.0},\n",
       "  'ar': {'auc': 0.8002750425617939, 'th_optim': 1.0}},\n",
       " 'llama': {'auc': 0.9431453061771782,\n",
       "  'th_optim': 1.0,\n",
       "  'en': {'auc': 0.9297217894764578, 'th_optim': 1.0},\n",
       "  'it': {'auc': 0.9954626969591409, 'th_optim': 1.0},\n",
       "  'de': {'auc': 0.9666838276130177, 'th_optim': 0.4055175781},\n",
       "  'ar': {'auc': 0.9905688685180518, 'th_optim': 0.99609375}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['en', 'it', 'de', 'ar']\n",
    "llm2S3_test_auc_dict = {}\n",
    "\n",
    "for model in [x for x in llm2s3_test.columns.to_list()[4:]]:\n",
    "    labels = llm2s3_test['label']\n",
    "    fpr, tpr, thresholds = roc_curve(labels, llm2s3_test[model])\n",
    "    llm2S3_test_auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "\n",
    "    for test_language in languages:\n",
    "        filtered = llm2s3_test[llm2s3_test.language == test_language]\n",
    "        if filtered.empty:\n",
    "            fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "        else:\n",
    "            fpr, tpr, thresholds = roc_curve(filtered['label'], filtered[model])\n",
    "        llm2S3_test_auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)] if len(thresholds) > 0 else 0}\n",
    "\n",
    "llm2S3_test_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a76a5",
   "metadata": {},
   "source": [
    "### 5.2.2 Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e094cc60-09ba-4bea-9306-b20b8c6d8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_th = 'th_optim'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbce95",
   "metadata": {},
   "source": [
    "#### Statistical detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec377e82-3dec-4eb7-b244-3d96ccb84f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() \n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_test['language'], llm2s3_test[selected])]\n",
    "selected = 'rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_test['language'], llm2s3_test[selected])]\n",
    "selected = 'binocular'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=llm2S3_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_test['language'], llm2s3_test[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f07428",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07484c36-520a-4a92-8055-5144bb09b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2s3 = pd.DataFrame()\n",
    "selected = 'llama'\n",
    "llm2s3[selected] = [1 if (lang in languages) and (prob>=llm2S3_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_test['language'], llm2s3_test[selected])]\n",
    "selected = 'mistral'\n",
    "llm2s3[selected] = [1 if (lang in languages) and (prob>=llm2S3_test_auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=llm2S3_test_auc_dict[selected][use_th]) else 0 for lang, prob in zip(llm2s3_test['language'], llm2s3_test[selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27a869",
   "metadata": {},
   "source": [
    "#### Two-step majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c44e81d3-5f1b-43af-8d79-bd05f1decd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical part majority voting\n",
    "llm2s3_test['s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(s5['entropy'], s5['rank'], s5['binocular'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24e8fb19-4eae-434a-96bb-1b156fd9a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final majority voting\n",
    "llm2s3_test['llm2s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(llm2s3['llama'], llm2s3['mistral'], llm2s3_test['s3'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad2d0e",
   "metadata": {},
   "source": [
    "### 5.2.3 Accuracy for LLM2S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33e6c126-57a7-4979-a1e6-5afd240a59e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98410   0.97534   0.97970     20238\n",
      "           1    0.97764   0.98559   0.98160     22140\n",
      "\n",
      "    accuracy                        0.98070     42378\n",
      "   macro avg    0.98087   0.98047   0.98065     42378\n",
      "weighted avg    0.98072   0.98070   0.98069     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(llm2s3_test['label'], llm2s3_test['llm2s3'], digits=5, output_dict=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
